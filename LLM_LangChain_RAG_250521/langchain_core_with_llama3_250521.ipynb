{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# > ollama run llama3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0163f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A question that has puzzled humans for centuries! 🤔\n",
      "\n",
      "So, why is the sky blue? Let me break it down in simple terms:\n",
      "\n",
      "**Short answer:** The sky appears blue because of a phenomenon called Rayleigh scattering.\n",
      "\n",
      "**Longer explanation:**\n",
      "\n",
      "When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases like nitrogen (N2) and oxygen (O2). These molecules are much smaller than the wavelength of light. As a result, they scatter shorter (blue) wavelengths more efficiently than longer (red) wavelengths.\n",
      "\n",
      "Think of it like a game of pool: when a cue ball hits a group of smaller balls, they bounce around in all directions, spreading out. Similarly, the blue light from the sun is scattered in all directions by these tiny molecules, reaching our eyes and making the sky appear blue.\n",
      "\n",
      "**Other factors:** While Rayleigh scattering is the main culprit behind the blue sky, other atmospheric conditions can influence its color:\n",
      "\n",
      "1. **Atmospheric particles:** Tiny aerosols like dust, pollen, or smoke can scatter light, making the sky appear more hazy or gray.\n",
      "2. **Clouds:** Clouds and fog can reflect sunlight, adding to the sky's brightness and sometimes changing its apparent color.\n",
      "3. **Angle of the sun:** The position of the sun in the sky affects its apparent color. When it's overhead, the light has to travel through less atmosphere, making it appear more intense and blue.\n",
      "\n",
      "So, there you have it! The beauty of the blue sky is a result of the harmonious combination of light, molecules, and atmospheric conditions. 🌌\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "stream = ollama.generate(model='llama3', prompt='하늘이 왜 파란지에 대한 답을 한글로 말해줘')\n",
    "print(stream['response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8279c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain/LangSmith API Key가 설정되지 않았습니다. 참고: https://wikidocs.net/250954\n"
     ]
    }
   ],
   "source": [
    "# https://wikidocs.net/233805\n",
    "\n",
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com   ---> Lang Smith 이해 먼저\n",
    "# !pip install langchain-teddynote\n",
    "\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"llama3_Model_20521\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8014a",
   "metadata": {},
   "source": [
    "### 랭체인 개요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 마스터 : 랭체인으로 완성하는 LLM 서비스 (p.31~)\n",
    "# 랭체인 주요 패키지\n",
    "\n",
    "## langchain-core : 랭체인 생태계의 기본이 되는 패키지로 다른 많은 패키지들이 이에 의존\n",
    "##                  대규모 언어모델, 데이터 벡터 저장소(Vector Store), 검색기(Retriever)와 같은 중요한 기능들을 정의하는 기본 구조 포함\n",
    "## langchain : 애플리케이션의 구조를 만드는 체인(chain), LLM을 사용해 작업을 처리하는 지능형 시스템인 에이전트(Agent),\n",
    "##             그리고 정보를 검색하는 검색기(retriever) 전략 등을 포함한다.\n",
    "## langchain-community : 랭체인 커뮤니티에서 유지 관리하는 다양한 타사 서비스 통합을 포함\n",
    "##                       LLM, Vector Store, Retriever 등을 선택적으로 사용 가능함.\n",
    "## 파트너 패키지 : langchain-[partner] -> langchain-openai, langchain-anthropic 등\n",
    "\n",
    "# 랭 그래프 : 그래프 기반 모델링 패키지\n",
    "# 랭 서브 : REST API 배포를 도와주는 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5793422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wonta\\AppData\\Local\\Temp\\ipykernel_10932\\713405683.py:7: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😊\n",
      "\n",
      "Deep learning is a subset of machine learning that uses artificial neural networks to analyze and learn from data. Here's a brief overview:\n",
      "\n",
      "**What are Neural Networks?**\n",
      "\n",
      "Artificial neural networks are composed of interconnected nodes (neurons) that process and transmit information. Each node applies an activation function to the weighted sum of its inputs, producing an output that is passed to subsequent nodes.\n",
      "\n",
      "**How do Deep Learning Models Work?**\n",
      "\n",
      "Deep learning models typically consist of multiple layers of neural networks, each processing a different level of abstraction in the data. The layers are designed to:\n",
      "\n",
      "1. **Extract features**: Early layers focus on simple features like edges and lines.\n",
      "2. **Recognize patterns**: Middle layers learn more complex patterns, such as shapes and textures.\n",
      "3. **Make predictions**: Later layers integrate information from previous layers to make final predictions or decisions.\n",
      "\n",
      "**Key Characteristics of Deep Learning:**\n",
      "\n",
      "1. **Hierarchical representations**: Deep learning models learn hierarchical representations of data, allowing them to capture complex relationships.\n",
      "2. **Large datasets**: Deep learning models require large datasets to train and improve their performance.\n",
      "3. **Multiple layers**: Multiple layers allow deep learning models to extract increasingly abstract features from the data.\n",
      "4. **Non-linear transformations**: Each layer applies non-linear transformations to the input data, enabling the model to learn complex relationships.\n",
      "\n",
      "**Applications of Deep Learning:**\n",
      "\n",
      "1. **Computer Vision**: Image recognition, object detection, facial recognition\n",
      "2. **Natural Language Processing (NLP)**: Text classification, sentiment analysis, language translation\n",
      "3. **Speech Recognition**: Speech-to-text systems and voice assistants\n",
      "4. **Robotics**: Control systems for robots and autonomous vehicles\n",
      "\n",
      "**Challenges and Limitations:**\n",
      "\n",
      "1. **Training time**: Deep learning models can be computationally intensive and require significant training time.\n",
      "2. **Data quality**: The quality of the training data is crucial, as poor-quality data can lead to poor performance or overfitting.\n",
      "3. **Interpretability**: Deep learning models can be difficult to interpret, making it challenging to understand their decision-making processes.\n",
      "\n",
      "That's a brief overview of deep learning! 💡"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "# Ollama 모델을 불러옵니다.\n",
    "llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "# 프롬프트\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic} 에 대하여 간략히 설명해 줘.\")\n",
    "\n",
    "# 체인 생성\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 간결성을 위해 응답은 터미널에 출력됩니다.\n",
    "answer = chain.stream({\"topic\": \"deep learning\"})\n",
    "\n",
    "# 스트리밍 출력\n",
    "stream_response(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364e4ea",
   "metadata": {},
   "source": [
    "### RAG(Retrieval-Augmented Ceneration) 검색 증강 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb86747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 외부 데이터베이스나 문서에서 정보를 검색하여 응답을 생성하는 방식\n",
    "# 랭체인으로 이러한 시스템을 구축하면 방대한 문서에서 필요한 정보를 찾아 정확한 답변 제공 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e922e",
   "metadata": {},
   "source": [
    "### 랭체인의 핵심 구성요소\n",
    "#### - 대규모 언어모델(LLM)\n",
    "#### - 체인(Chains)\n",
    "#### - 프롬프트(Prompts)\n",
    "#### - 파서(Parsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de694143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama3 클라이언트를 이용,\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "client = ChatOllama()   # 모델을 미리 정의하지 않고 시작\n",
    "# client = Chatollama(model = \"llama3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e24fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I think you meant \"Double Deep\" as in Double Deeper, a popular Korean fashion trend! 😊\\n\\nDouble Deeper refers to wearing two layers of clothing that are typically worn separately, such as a sweater over a shirt, or a dress over leggings. This fashion trend is characterized by layering different textures, colors, and patterns to create a unique and stylish look.\\n\\nIn Korea, Double Deeper has become a popular way for young women to express themselves through fashion, experimenting with different combinations of clothing items to create a bold and eye-catching style. It\\'s all about mixing and matching different pieces to create a one-of-a-kind outfit! 💃'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 러너블 표준 인터페이스\n",
    "# 여러 공통 메서드를 제공하는 표준 인터페이스를 사용\n",
    "\n",
    "# 파이프 연산자\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "\n",
    "# {topic}에 대한 설명을 요청하는 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"주제 {topic}에 대해 짧은 설명을 해주세요.\"\n",
    ")\n",
    "\n",
    "# 출력 파서를 문자열로 설정\n",
    "output_parser = StrOutputParser()\n",
    "client = ChatOllama(model = \"llama3\")  \n",
    "\n",
    "# 파이프라인 설정 : 주제 입력 -> 프롬프트 생성 -> 모델로 응답 생성 -> 문자열로 파싱\n",
    "chain = (\n",
    "    {\"topic\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | client\n",
    "    | output_parser\n",
    ")\n",
    "\n",
    "# \"더블딥\" 주제로 설명 요청\n",
    "\n",
    "chain.invoke(\"더블딥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa2f1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s the translation:\\n\\nI\\'d be happy to provide a brief overview on the topic \"더블딥\" (Double Deep).\\n\\nDouble Deep is a type of neural network architecture that consists of two hidden layers, each with its own set of learnable weights and biases. This architecture is designed to improve the performance of deep learning models by increasing the capacity of the model to represent complex relationships between inputs and outputs.\\n\\nThe Double Deep architecture is particularly useful for tasks such as image classification, object detection, and sequence prediction, where the presence of multiple hidden layers can help to capture subtle patterns and features in the data. The additional layer also provides more opportunities for the model to learn non-linear representations of the input data, which can lead to improved predictive accuracy.\\n\\nOverall, Double Deep is a powerful architecture that has been shown to be effective in a wide range of applications, from computer vision to natural language processing.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p. 56~\n",
    "# 질문을 생성하는 템플릿 정의\n",
    "analysis_prompt = ChatPromptTemplate.from_template(\"이 대답을 영어로 번역해 주세요: {answer}\")\n",
    "\n",
    "# 이전에 정의된 체인과 새로운 작업을 연결하는 체인 구성\n",
    "composed_chain = {\"answer\" : chain} | analysis_prompt | client | StrOutputParser()\n",
    "\n",
    "# \"더블딥\" 이라는 주제로 응답을 생성하고 체인 실행\n",
    "composed_chain.invoke({\"topic\" : \"더블딥\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b376385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실행되는 순서 : 결합된 체인(composed chain)은 아래의 연속된 작업을 자동을 처리함\n",
    "\n",
    "# \"answer\"라는 키에 앞서 정의된 chain에서 생성된 응답 입력\n",
    "# 이 응답을 영어로 번역하는 프롬프트로 전달\n",
    "# client(llama3) 실행하여 번역된 응답을 생성\n",
    "# StrOutpuParser를 통해 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6866ca9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is the translation:\\n\\nThe \"Double Deep\" topic refers to the concept of using two or more neural network architectures, each with its own set of weights and biases, in a hierarchical manner to solve complex problems.\\n\\nIn traditional deep learning approaches, a single neural network is used to learn features from raw data. In contrast, Double Deep models use multiple networks, often with different architectures or specializations, to learn features at different levels of abstraction.\\n\\nThis approach can be useful for tasks that require processing multiple types of information or handling complex relationships between variables. For example, in natural language processing (NLP), a Double Deep model might consist of a first network that learns word-level representations and a second network that learns sentence-level representations to capture contextual dependencies.\\n\\nBy combining the strengths of multiple networks, Double Deep models can potentially achieve better performance, improved robustness, or even novel capabilities compared to single-network approaches. 💡'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 람다 함수를 사용하여 입력 데이터를 다른 형식으로 변환한 후 체인에 연결하는 방법 (p.58)\n",
    "\n",
    "# 이전에 정의된 값들\n",
    "model = ChatOllama(model = \"llama3\")\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대해 짧은 설명을 해주세요.\"\n",
    ")\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "analysis_prompt = ChatPromptTemplate.from_template(\"이 대답을 영어로 번역해 주세요: {answer}\")\n",
    "\n",
    "# 람다 함수를 사용한 Chain 구성\n",
    "composed_chain_with_lambda = (\n",
    "    # 이전에 정의된 Chain을 사용하여 입력 데이터 받아오기\n",
    "    chain\n",
    "\n",
    "    # 입력 데이터를 \"answer\" 키로 변환하는 람다 함수\n",
    "    | (lambda input : {\"answer\" : input})\n",
    "\n",
    "    # \"answer\" 키를 가진 데이터를 영어로 번역하도록 프롬프트에 전달\n",
    "    | analysis_prompt\n",
    "\n",
    "    # 프롬프트에서 생성된 요청을 모델에 전다하여 결과를 생성\n",
    "    | model\n",
    "\n",
    "    # 모델에서 변환된 결과를 문자열로 파싱\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# \"더블딥\" 이라는 주제로 답변을 생성하고, 영어로 번역\n",
    "composed_chain_with_lambda.invoke({\"topic\" \" 더블딥\"})\n",
    "\n",
    "# invoke() 메서드 - 체인 실행\n",
    "# 람다 함수를 사용하여 입력을 변환하는 방식은 스트리밍 작업과 호환되지 않을 수 있음 주의 (p.59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652403cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
